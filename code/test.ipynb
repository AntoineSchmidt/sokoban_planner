{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import time\n",
    "import copy\n",
    "import tqdm\n",
    "import random\n",
    "import pickle\n",
    "\n",
    "import gym\n",
    "import gym_sokoban\n",
    "\n",
    "from utils import *\n",
    "from network import *\n",
    "from exploration import *\n",
    "\n",
    "from dqn import *\n",
    "from ppo import *\n",
    "from replay import *\n",
    "\n",
    "from astar import *\n",
    "from mcts import *\n",
    "from mcts_improved import *\n",
    "\n",
    "from manage import *\n",
    "startSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create test Sokoban problems\n",
    "\n",
    "sokoban_test = Sokoban(count=1000)\n",
    "sokoban_test.all_envs += Sokoban(count=1000, size=(14, 19), steps=100).all_envs # bigger problems\n",
    "with open('data/sokoban_test.pkl', 'wb') as f:\n",
    "    pickle.dump(sokoban_test, f)\n",
    "\n",
    "sokoban_test_small = Sokoban(count=0)\n",
    "for i in range(1, 4):\n",
    "    sokoban_test_small.all_envs += Sokoban(boxes=i, count=50, size=(7, 7)).all_envs\n",
    "with open('data/sokoban_test_small.pkl', 'wb') as f:\n",
    "    pickle.dump(sokoban_test_small, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load small test envs\n",
    "with open('data/sokoban_test_small.pkl', 'rb') as f:\n",
    "    sokoban_test_small = pickle.load(f)\n",
    "\n",
    "\n",
    "# select envs to test on\n",
    "def select(boxes):\n",
    "    indizes = []\n",
    "    for i in range(len(sokoban_test_small.all_envs)):\n",
    "        env = sokoban_test_small.get(i)[0]\n",
    "        if boxes[env.num_boxes - 1] > 0:\n",
    "            boxes[env.num_boxes - 1] -= 1\n",
    "            indizes.append(i)\n",
    "            #draw(env, \"images/exploration/test_{}.png\".format(i))\n",
    "        if sum(boxes) == 0: break\n",
    "\n",
    "    indizes.sort(key = lambda entry: sokoban_test_small.all_envs[entry][0].num_boxes)\n",
    "    return indizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test time usage of gym action and env copy\n",
    "\n",
    "time_copy = 0\n",
    "time_step = 0\n",
    "\n",
    "for i in range(split):\n",
    "    env = sokoban_test_small.get(i)[0]\n",
    "\n",
    "    # copy\n",
    "    start = time.time()\n",
    "    copy.deepcopy(env)\n",
    "    time_copy += time.time() - start\n",
    "\n",
    "    # step\n",
    "    start = time.time()\n",
    "    env.step(0, 'tiny_rgb_array')\n",
    "    time_step += time.time() - start\n",
    "\n",
    "# ff takes ~0.01 seconds to solve most problems\n",
    "print(time_copy / split, time_step / split)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Fast Forward</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analyze solutions for generated sokoban problems\n",
    "\n",
    "def analyze(problems):\n",
    "    max_length = [0] * 3\n",
    "    length = np.zeros((500, 3))\n",
    "    for env, plan in problems.all_envs:\n",
    "        solution = len(plan)\n",
    "        if solution > max_length[env.num_boxes - 1]:\n",
    "            max_length[env.num_boxes - 1] = solution\n",
    "        length[solution][env.num_boxes - 1] += 1\n",
    "\n",
    "    print(max_length)\n",
    "    x = np.arange(max(max_length) + 1)\n",
    "    x_max = min(100, x[-1])\n",
    "    for i in range(3):\n",
    "        label = '1 Box' if i == 0 else '{} Boxes'.format(i + 1)\n",
    "        x_range = min(x_max, max_length[i])\n",
    "        average_length = np.sum(length[:len(x), i] * x) / np.sum(length[:len(x), i])\n",
    "        plt.axvline(average_length, linestyle=':', color='C{}'.format(i))\n",
    "        plt.plot(x[:x_range], length[:x_range, i], label=label, color='C{}'.format(i))\n",
    "\n",
    "    plt.ylabel('Count')\n",
    "    plt.xlabel('Length')\n",
    "    plt.legend()\n",
    "    plt.savefig('data/sokoban_train.png', bbox_inches='tight', dpi=200)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "with open('data/sokoban_train.pkl', 'rb') as f: analyze(pickle.load(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# planner behaviour\n",
    "\n",
    "for i in range(len(sokoban_test_small.all_envs)):\n",
    "    env, plan, _ = sokoban_test_small.get(i)\n",
    "    if env.num_boxes > 2:\n",
    "        for action in range(len(plan)):\n",
    "            done = env.step(action_translator[plan[action]], 'tiny_rgb_array')[2]\n",
    "            if done: assert(action + 1 == len(plan))\n",
    "            plan_new = solve(env)\n",
    "            if (len(plan_new) * 0.8) > (len(plan) - action - 1):\n",
    "                draw(sokoban_test_small.get(i)[0], 'images/behaviour/state-{}.png'.format(i))\n",
    "                draw(env, 'images/behaviour/state-{}-sub.png'.format(i))\n",
    "                print(len(plan), len(plan[action + 1:]))\n",
    "                print(len(plan_new))\n",
    "                break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Search</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_s(callback, problems):\n",
    "    total_envs = np.zeros((3,))\n",
    "    total_solved = np.zeros((3,))\n",
    "    total_time = [[], [], []]\n",
    "    total_quality = [[], [], []]\n",
    "\n",
    "    for env, plan in tqdm(problems.all_envs):\n",
    "        envc = copy.deepcopy(env)\n",
    "\n",
    "        start = time.time()\n",
    "        path = callback(envc)\n",
    "        end = time.time()\n",
    "\n",
    "        total_envs[env.num_boxes - 1] += 1\n",
    "        if path:\n",
    "            total_solved[env.num_boxes - 1] += 1\n",
    "            total_time[env.num_boxes - 1].append(end - start)\n",
    "            total_quality[env.num_boxes - 1].append(len(path) / len(plan))\n",
    "\n",
    "    for i in range(3):\n",
    "        output = \"& {} & {} & {} ({}) & {} ({})\"\n",
    "        print(output.format(i + 1, np.round(total_solved[i] / total_envs[i], 2),\n",
    "                            np.round(np.average(total_time[i]), 2), np.round(np.std(total_time[i]), 2),\n",
    "                            np.round(np.average(total_quality[i]), 2), np.round(np.std(total_quality[i]), 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Config.early_stop = False\n",
    "\n",
    "\n",
    "print('astar, BFS as no heuristic is used')\n",
    "evaluate_s(lambda env: search_astar(env, cutoff=1e4), sokoban_test_small)\n",
    "\n",
    "print('mcts')\n",
    "evaluate_s(lambda env: search_mcts(env, cutoff=1e4, prune=False), sokoban_test_small)\n",
    "\n",
    "print('mcts, pruned')\n",
    "evaluate_s(lambda env: search_mcts(env, cutoff=1e4, prune=True), sokoban_test_small)\n",
    "\n",
    "print('mcts_improved')\n",
    "evaluate_s(lambda env: search_mcts_improved(env, cutoff=1e4, prune=False), sokoban_test_small)\n",
    "\n",
    "print('mcts_improved, pruned')\n",
    "evaluate_s(lambda env: search_mcts_improved(env, cutoff=1e4, prune=True), sokoban_test_small)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Exploration</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_e(env, plan, exploration, ff=True):\n",
    "    agent = DQNAgent(exploration=exploration)\n",
    "    replay = Replay(augment=False)\n",
    "\n",
    "    iterations = 0\n",
    "    while True:\n",
    "        iterations += 1\n",
    "        dqn_episode(copy.deepcopy(env), agent, replay, max_steps=int(len(plan) * 1.5))\n",
    "\n",
    "        if ff and iterations % 10 == 0: # add ff transitions\n",
    "            dqn_episode(copy.deepcopy(env), agent, replay, path=plan, train=False) # comparable gradient steps\n",
    "\n",
    "        # evaluation\n",
    "        total_reward, done, steps, total_loss = dqn_episode(copy.deepcopy(env), agent, replay,\n",
    "                                                            max_steps=2 * len(plan), evaluation=True)\n",
    "\n",
    "        if done: return iterations, steps / len(plan) # learning episodes, solution quality\n",
    "        #agent.exploration.anneal()\n",
    "\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs = 5 # runs per env\n",
    "settings = [EGreedy(epsilon=0.5), EGreedy(epsilon=0.25), Boltzmann(tau=0.5), Boltzmann(tau=0.25), UCB1()]\n",
    "stats = []\n",
    "\n",
    "for e in select([2] * 3): # test on 2 envs for every box number\n",
    "    results = []\n",
    "    env, plan, _ = sokoban_test_small.get(e)\n",
    "    print('ff ratio', len(plan) / len(search_astar(env)))\n",
    "\n",
    "    # collect data\n",
    "    for i in range(runs):\n",
    "        print(e, i)\n",
    "\n",
    "        for setting in copy.deepcopy(settings):\n",
    "            results.append(evaluate_e(env, plan, setting))\n",
    "            print(results[-1])\n",
    "\n",
    "\n",
    "    # aggregate data, number of iterations until evaluation solve and path quality (solution / ff)\n",
    "    for i in range(len(settings)):\n",
    "        mode = results[i::len(settings)]\n",
    "\n",
    "        for j in range(2):\n",
    "            stats.append([x[j] for x in mode])\n",
    "            print(stats[-1])\n",
    "\n",
    "\n",
    "with open('data/test_exploration.pkl', 'wb') as f:\n",
    "    pickle.dump(stats, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/test_exploration.pkl', 'rb') as f:\n",
    "    stats = pickle.load(f)\n",
    "\n",
    "indizes = select([2] * 3)\n",
    "settings = len(stats) // len(indizes)\n",
    "\n",
    "\n",
    "# plot results\n",
    "cell = 0\n",
    "for i in range(len(indizes)):\n",
    "    # images\n",
    "    cell += 1\n",
    "    plt.subplot(3, 4, cell)\n",
    "    plt.imshow(sokoban_test_small.get(indizes[i])[0].get_image(mode='rgb_array'))\n",
    "    plt.axis('off')\n",
    "\n",
    "\n",
    "    cell += 1\n",
    "    ax1 = plt.subplot(3, 4, cell)\n",
    "    ax2 = ax1.twiny()\n",
    "    plt.yticks([])\n",
    "    plt.ylim(-1, 5)\n",
    "    y = np.arange(settings / 2)[::-1]\n",
    "\n",
    "    # iterations\n",
    "    x, std = [], []\n",
    "    for s in range(i * settings, i * settings + settings, 2):\n",
    "        x.append(np.average(stats[s]))\n",
    "        std.append(np.std(stats[s]))\n",
    "\n",
    "    ax1.errorbar(x, y, xerr=std, linestyle='None', marker='o', capsize=3, color='C0')\n",
    "    ax1.spines['bottom'].set_color('C0')\n",
    "\n",
    "    # quality\n",
    "    x, std = [], []\n",
    "    for s in range(i * settings, i * settings + settings, 2):\n",
    "        x.append(np.average(stats[s + 1]))\n",
    "        std.append(np.std(stats[s + 1]))\n",
    "\n",
    "    ax2.errorbar(x, y, xerr=std, linestyle='None', marker='+', capsize=0, color='C1')\n",
    "    ax2.spines['top'].set_color('C1')\n",
    "\n",
    "plt.tight_layout(0.2)\n",
    "plt.savefig('data/test_exploration.png', bbox_inches='tight', dpi=200)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# print latex table\n",
    "for i in range(settings // 2):\n",
    "    line = []\n",
    "    for b in range(3): # boxes\n",
    "        iterations = []\n",
    "        quality = []\n",
    "        for j in range(2): # 2 envs per box\n",
    "            index = (b * 2 + j) * settings + 2 * i\n",
    "            iterations += stats[index]\n",
    "            quality += stats[index + 1]\n",
    "\n",
    "        output = '& {} & {} ({}) & {} ({})'\n",
    "        print(output.format(b + 1, np.round(np.average(iterations), 2), np.round(np.std(iterations), 2),\n",
    "                            np.round(np.average(quality), 2), np.round(np.std(quality), 2)))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Network</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load evaluation envs\n",
    "\n",
    "with open('data/sokoban_train.pkl', 'rb') as f:\n",
    "    sokoban_problems = pickle.load(f)\n",
    "\n",
    "split = int(0.1 * len(sokoban_problems.all_envs))\n",
    "sokoban_problems.all_envs = sokoban_problems.all_envs[:split]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# average trained networks\n",
    "\n",
    "if True:\n",
    "    model, _ = create()\n",
    "    model.set_weights(np.array(model.get_weights()) * 0)\n",
    "    models = ['2020-07-12_03-54-48', '2020-07-10_17-34-19', '2020-07-10_19-12-07']\n",
    "    for i in models:\n",
    "        model_temp, _ = create()\n",
    "        model_temp.load_weights('models/il_action_exploration/{}.h5'.format(i))\n",
    "        model.set_weights(np.array(model.get_weights()) + 1/len(models) * np.array(model_temp.get_weights()))\n",
    "    model.save_weights('models/il_action_exploration.h5')\n",
    "else:\n",
    "    model, _ = create(activation_out='linear')\n",
    "    model.set_weights(np.array(model.get_weights()) * 0)\n",
    "    models = ['2020-07-09_06-55-58', '2020-07-11_06-40-27', '2020-07-11_17-51-45']\n",
    "    for i in models:\n",
    "        model_temp, _ = create()\n",
    "        model_temp.load_weights('models/rl_qaction_dqn/{}.h5'.format(i))\n",
    "        model.set_weights(np.array(model.get_weights()) + 1/len(models) * np.array(model_temp.get_weights()))\n",
    "    model.save_weights('models/rl_qaction_dqn.h5')\n",
    "\n",
    "print(evaluate(model, sokoban_problems))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate networks greedily\n",
    "\n",
    "all_solved = []\n",
    "\n",
    "# policy network\n",
    "model, _ = create()\n",
    "for net in ['models/il_action.h5', 'models/il_action_exploration.h5', 'models/rl_action_ppo.h5']:\n",
    "    stats = []\n",
    "    model.load_weights(net)\n",
    "    print(net, evaluate(model, sokoban_problems, stats=stats))\n",
    "    all_solved.append(stats)\n",
    "\n",
    "# q-value network\n",
    "model, _ = create(activation_out='linear')\n",
    "for net in ['models/il_qaction.h5', 'models/rl_qaction_dqn.h5']:\n",
    "    stats = []\n",
    "    model.load_weights(net)\n",
    "    print(net, evaluate(model, sokoban_problems, stats=stats))\n",
    "    all_solved.append(stats)\n",
    "\n",
    "\n",
    "# analyze policy correlation\n",
    "policy_a, policy_b = 1, 4\n",
    "\n",
    "policy_a = all_solved[policy_a]\n",
    "policy_b = all_solved[policy_b]\n",
    "values = [[0,0,0] for _ in range(3)]\n",
    "for i in policy_a:\n",
    "    index = sokoban_problems.all_envs[i][0].num_boxes - 1\n",
    "    if i in policy_b: values[1][index] +=1\n",
    "    else: values[0][index] += 1\n",
    "\n",
    "for i in policy_b:\n",
    "    if i not in policy_a:\n",
    "        index = sokoban_problems.all_envs[i][0].num_boxes - 1\n",
    "        values[2][index] += 1\n",
    "\n",
    "\n",
    "print(values) # [[11, 66, 73], [347, 229, 141], [2, 12, 22]]\n",
    "\n",
    "barWidth = 0.25\n",
    "labels = ['only policy', 'both', 'only q-value']\n",
    "boxes = np.arange(3)\n",
    "for i in range(3):\n",
    "    plt.bar(boxes + i * barWidth, values[i], width=barWidth, color='C{}'.format(i), edgecolor='white', label=labels[i])\n",
    "\n",
    "plt.xticks(boxes + barWidth, ['1 Box', '2 Boxes', '3 Boxes'])\n",
    "\n",
    "plt.legend()\n",
    "plt.savefig('images/policy_correlation.png', bbox_inches='tight', dpi=200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate combined value + policy performance\n",
    "\n",
    "model_p, _ = create()\n",
    "model_p.load_weights('models/il_action_exploration.h5')\n",
    "\n",
    "model_v, _ = create(activation_out='linear')\n",
    "model_v.load_weights('models/rl_qaction_dqn.h5')\n",
    "\n",
    "class combined_model():\n",
    "    def predict(data):\n",
    "        return 0.5 * (model_p.predict(data) + softmax(model_v.predict(data), tau=0.1))\n",
    "\n",
    "print(evaluate(combined_model, sokoban_problems))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# policy entropy\n",
    "\n",
    "model, _ = create()\n",
    "model.load_weights('models/il_action_exploration.h5')\n",
    "\n",
    "#model, _ = create(activation_out='linear')\n",
    "#model.load_weights('models/rl_qaction_dqn.h5')\n",
    "\n",
    "for env, plan in sokoban_problems.all_envs:\n",
    "    trace = []\n",
    "    entropy = []\n",
    "    env = copy.deepcopy(env)\n",
    "\n",
    "    for j in range(2 * len(plan)):\n",
    "        env_h = hash(str(strip(env)))\n",
    "        if env_h in trace: break\n",
    "        else: trace.append(env_h)\n",
    "\n",
    "        env_b = binary(strip(env))[0]\n",
    "        policy = model.predict(np.expand_dims(env_b, axis=0))[0]\n",
    "        #policy = softmax(policy, tau=0.1)\n",
    "        entropy.append(-sum(policy * np.log(policy + 1e-10)))\n",
    "\n",
    "        action = np.argmax(policy) # best predicted action\n",
    "        _, reward, done, info = env.step(action_translator[action], 'tiny_rgb_array')\n",
    "\n",
    "        if done: break\n",
    "    if not done:\n",
    "        plt.plot(np.arange(len(entropy)), entropy, color='C0' if done else 'C1')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evalute policy accuracy\n",
    "\n",
    "model, _ = create()\n",
    "model.load_weights('models/il_action_exploration.h5')\n",
    "\n",
    "accuracy = np.zeros((3,2))\n",
    "for i in range(len(sokoban_problems.all_envs)):\n",
    "    env, plan, _ = sokoban_problems.get(i)\n",
    "    for action in plan:\n",
    "        output = model.predict(np.expand_dims(binary(strip(env))[0], axis=0))[0]\n",
    "        if np.argmax(output) == action:\n",
    "            accuracy[env.num_boxes - 1][0] += 1\n",
    "        accuracy[env.num_boxes - 1][1] += 1\n",
    "        if env.step(action_translator[action], 'tiny_rgb_array')[2]: break\n",
    "\n",
    "print(accuracy[:, 0] / accuracy[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate length heuristic with astar\n",
    "\n",
    "Config.early_stop = False\n",
    "\n",
    "\n",
    "model = {}\n",
    "evaluate_s(lambda env: search_astar(env, model, cutoff=1e3, w=1.0), sokoban_problems)\n",
    "\n",
    "model['heuristic'] = Sokoban\n",
    "evaluate_s(lambda env: search_astar(env, model, cutoff=1e3, w=1.0), sokoban_problems)\n",
    "\n",
    "model['heuristic'] = create(shape_out=1, activation_out='linear')[0]\n",
    "for net in ['models/il_length.h5', 'models/il_length_mae.h5', 'models/il_length_exploration.h5']:\n",
    "    model['heuristic'].load_weights(net)\n",
    "    evaluate_s(lambda env: search_astar(env, model, cutoff=1e3, w=1.0), sokoban_problems)\n",
    "    evaluate_s(lambda env: search_astar(env, model, cutoff=1e3, w=3.0), sokoban_problems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate network and search combinations\n",
    "\n",
    "Config.early_stop = True\n",
    "\n",
    "\n",
    "model = {}\n",
    "if True:\n",
    "    model['policy'] = create()[0]\n",
    "    model['policy'].load_weights('models/il_action_exploration.h5')\n",
    "if False:\n",
    "    model['policy'] = combined_model\n",
    "if False:\n",
    "    model['value'] = create()[0]\n",
    "    model['value'].load_weights('models/rl_qaction_dqn.h5')\n",
    "if True:\n",
    "    model['heuristic'] = create(shape_out=1, activation_out='linear')[0]\n",
    "    model['heuristic'].load_weights('models/il_length_exploration.h5')\n",
    "\n",
    "evaluate_s(lambda env: search_astar(env, model, cutoff=1e10, w=3.0), sokoban_problems)\n",
    "#evaluate_s(lambda env: search_mcts_improved(env, model, cutoff=1e3), sokoban_problems)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
